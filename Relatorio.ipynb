{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto - Séries Temporais\n",
    "## Residência em Ciência de Dados - SAMSUNG/UFPE\n",
    "\n",
    "### Alunos:\n",
    "- Lucas Couri (lncc2)\n",
    "- Mariama Oliveira (mcso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as tsa\n",
    "#from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "import pmdarima as pm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "#import matplotlib as mpl\n",
    "#import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#mpl.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos o dataset disponível no Kaggle sobre as temperaturas médias em Delhi (https://www.kaggle.com/datasets/mahirkukreja/delhi-weather-data). O dataset já era dividido em train e test, portanto, juntamos os dois datasets para depois separar em train e test da forma desejada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/datasets/mahirkukreja/delhi-weather-data\n",
    "df = pd.read_csv(\"temp_delhi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"date\", \"meantemp\"]]\n",
    "df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y')\n",
    "df.set_index(df['date'], inplace=True) \n",
    "df = df.drop('date', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando dados em treino, teste e validação. Vale notar que para os modelos lineares utilizaremos apenas treino (75%) e teste (25%), enquanto que para os modelos de machine learning utilizaremos treino (50%), validação (25%) e teste (25%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[:int(len(df) * 0.75)]\n",
    "df_test = df.iloc[int(len(df) * 0.75):]\n",
    "\n",
    "#df_train2 = df.iloc[:int(len(df) * 0.5)]\n",
    "#df_valid2 = df.iloc[int(len(df) * 0.5):int(len(df) * 0.75)]\n",
    "#df_test2 = df.iloc[int(len(df) * 0.75):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções de apoio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas funções construídas para exibir e salvar as métricas de cada modelo e plotar os gráficos de ajuste e predição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(y_test,prediction, results, name):\n",
    "    print(f'{name} - model Results')\n",
    "    print('r2' , r2_score(prediction, y_test))\n",
    "    print('mse' ,mean_squared_error(prediction, y_test))\n",
    "    print('mae', mean_absolute_error(prediction, y_test))\n",
    "    print('mape', mean_absolute_percentage_error(prediction, y_test))\n",
    "    results[name] = {'r2':r2_score(prediction, y_test), \\\n",
    "                    'mse': mean_squared_error(prediction, y_test), \n",
    "                    'mae': mean_absolute_error(prediction, y_test),\n",
    "                    'mape': mean_absolute_percentage_error(prediction, y_test)}\n",
    "\n",
    "def graf_ajuste(pred, train, titulo):\n",
    "    #Previsão do treino\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(pred, label='pred')\n",
    "    ax.plot(train, label='true')\n",
    "    plt.title(titulo)\n",
    "    plt.legend()\n",
    "\n",
    "def graf_pred(fc, train, test, titulo, SVR=False):\n",
    "    \n",
    "    fc_series = pd.Series(fc, index=test.index[1:])\n",
    "\n",
    "    #if(SVR==True):\n",
    "    #    fc = fitted\n",
    "    #    fc_series = pd.Series(fc, index=test.index[1:])\n",
    "    #else:\n",
    "        #fitted2 = fitted.apply(test)\n",
    "        #fc = fitted2.predict(start='2016-03-28', end='2017-04-24')  # 95% conf\n",
    "        #fc_series = pd.Series(fc, index=test.index)\n",
    "\n",
    "    # Plot\n",
    "    #plt.figure(figsize=(12,5), dpi=100)\n",
    "    plt.plot(train, label='Treino')\n",
    "    plt.plot(test, label='Teste')\n",
    "    plt.plot(fc_series, label='Predição')\n",
    "    plt.title(titulo)\n",
    "    plt.legend(loc='upper left', fontsize=8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotando a série temporal da temperatura média de Delhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()\n",
    "plt.title(\"Temperatura Média - Delhi\")\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Temperatura\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Através da decomposição verificamos que há tendência e sazonalidade, portanto a série não deve ser estacionária, vamos verificar a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 6, 4\n",
    "df_decomp = tsa.seasonal_decompose(df, period=365)\n",
    "df_decomp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelação e Estacionariedade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a função de auto correlação abaixo não decai  para zero, suspeitamos de que a série não seja estacionária. Vamos verificar a seguir por meio de um teste de hipótese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando um nível de confiança de 0,05 verificamos que o teste de Dickey-Fuller nos leva a não rejeitar a hipótese nula de não estacionariedade, visto que o p-valor = 0,149 (>0,05). Portanto, temos evidências que a série não é estacionária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, pvalue, lags, obs, critic, ic = tsa.stattools.adfuller(df)\n",
    "print(pvalue)\n",
    "print(lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferenciação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diff().plot()\n",
    "plt.title(\"Série diferenciada\")\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Temperatura\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após diferenciar a série aparenta ser estacionária, vamos verificar com o teste de Dickey-Fuller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diff().plot.hist()\n",
    "plt.title(\"Histograma da série diferenciada\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd1 = df.diff().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o p-valor<0,05 então decidimos rejeitar a hipótese nula de não estacionariedade à um nível de confiança de 0,05. Portanto, após diferenciar uma vez a série temos evidências para acreditar que a série se tornou estacionária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, pvalue, lags, obs, critic, ic = tsa.stattools.adfuller(dfd1)\n",
    "print(pvalue)\n",
    "print(lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelação da série diferenciada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlação com série diferenciada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd1.corrwith(dfd1.shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(dfd1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos a partir do comportamento da função de autocorrelação acima que os lags são significantes até o lag 3, e a partir dele se tornam não significativos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelação Parcial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlação Parcial com série diferenciada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(dfd1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos a partir da função de autocorrelação parcial acima que a partir do lag5 os lags se tornam não significativos. Analisando de forma mais conservadora é possível argumentar que o lag5 está bem próximo do limite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.index = pd.DatetimeIndex(df_train.index.values, freq=df_train.index.inferred_freq)\n",
    "#df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para realizar o ajuste dos modelos ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_arima(p,d,q,data):\n",
    "    arima_model = ARIMA(data, order=(p,d,q))\n",
    "    res_arima = arima_model.fit()\n",
    "    print(res_arima.summary())\n",
    "    res_arima.plot_diagnostics()\n",
    "    return res_arima\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA (5,1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir da analise dos gráficos da função de autocorrelação e autocorrelação parcial decidimos ajustar um ARIMA (5,1,3) visto que a série se torna estacionária após uma diferenciação, há decaimento após lag 3 do gráfico de autocorrelação e também há um corte após o lag 5 do gráfico de autocorrelação parcial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_arima_1 = perform_arima(5,1,3,df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_arima_1_test = res_arima_1.apply(df_test)\n",
    "fc = res_arima_1_test.predict(start='2016-03-28', end='2017-04-24')\n",
    "graf_pred(fc, df_train, df_test, 'Delhi - ARIMA (5,1,3) - Predição')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(df_test[1:], fc, results, 'ARIMA(5,1,3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do diagnóstico verificamos que os resíduos aparentam ser ruído branco (como deve ser em um bom ajuste)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA (4,1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também decidimos testar o ARIMA (4,1,3) visto que, com um olhar mais conservador, o corte na função de autocorrelação parcial pode ser visto como no lag 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_arima_2 = perform_arima(4,1,3,df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do diagnóstico verificamos que os resíduos aparentam ser ruído branco (como deve ser em um bom ajuste)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_ajuste(res_arima_2.predict(), df_train, 'Delhi - ARIMA (4,1,3) - Treino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_arima_2_test = res_arima_2.apply(df_test)\n",
    "fc = res_arima_2_test.predict(start='2016-03-28', end='2017-04-24')\n",
    "graf_pred(fc, df_train, df_test, 'Delhi - ARIMA (4,1,3) - Predição')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(df_test[1:], fc, results, 'ARIMA(4,1,3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA (0,1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o comportamento da funções de autocorrelação e autocorrelação parcial em algumas partes não foi tão claro, sem um decaímento exponencial muito evidente, decidimos também avaliar a hipótese de que há o corte brusco na função de autocorrelação, configurando um MA(3), dessa forma avaliamos o modelo ARIMA(0,1,3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_arima_3 = perform_arima(0,1,3,df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do diagnóstico verificamos que os resíduos aparentam ser ruído branco (como deve ser em um bom ajuste)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_arima_3_test = res_arima_3.apply(df_test)\n",
    "fc = res_arima_3_test.predict(start='2016-03-28', end='2017-04-24')\n",
    "graf_pred(fc, df_train, df_test, 'Delhi - ARIMA (0,1,3) - Predição')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(df_test[1:], fc, results, 'ARIMA(0,1,3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima = pm.auto_arima(df_train, max_ar=10, max_ma=5, max_d=2, seasonal=False, trace=True, stepwise=True) #verificar forcar estacionario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Auto ARIMA nos informa que, dentre os modelos testados, o ARIMA (2,0,1) é o modelo com o menor AIC (Critério de Informação de Akaike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima.plot_diagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do diagnóstico verificamos que os resíduos aparentam ser ruído branco (como deve ser em um bom ajuste)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotando ajuste do modelo aos dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_ajuste(auto_arima.predict_in_sample(), df_train.values, 'Delhi - Auto ARIMA(2,0,1) - Treino')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotando Treino, teste e predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model = ARIMA(df_train, order=(2, 0, 1))  \n",
    "res_arima_4 = auto_model.fit()\n",
    "res_arima_4_test = res_arima_4.apply(df_test)\n",
    "fc = res_arima_4_test.predict(start='2016-03-28', end='2017-04-24')\n",
    "graf_pred(fc, df_train, df_test, 'Delhi - ARIMA (2,0,1) - Predição')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(df_test[1:], fc, results, 'ARIMA(2,0,1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram gerados modelos utilizando três métodos de ML (KNN, SVR e MLP). Espera-se que com estes métodos seja possível capturar também relações não lineares existentes na série."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, foi necessário realizar feature engineering no dados da série a fim de criar features relevantes para os modelos.\n",
    "\n",
    "Foi utilizada a função **get_lags**, a qual cria features que correspodem a atrasos da série temporal. O número de atrasos  pode ser determinado a partir da análise do correlograma utilizando a quantidade de lags correlacionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time travel\n",
    "def get_lags(series, lags):\n",
    "  result = []\n",
    "  if lags > 0:\n",
    "    for lag in range(1, lags+1):\n",
    "    #  print(lag)\n",
    "    #  print(series.shift(lag))\n",
    "      result.append(series.shift(lag).rename({series.columns[0]: series.columns[0]+'-'+str(lag)}, axis=1))\n",
    "    #return result\n",
    "    return pd.concat(result, axis=1, names=list(range(-1,-lags))).dropna()\n",
    "  else:\n",
    "    for lag in range(-1, lags-1,-1):\n",
    "      #print(lag)\n",
    "      #print(series.shift(lag))\n",
    "      result.append(series.shift(lag).rename({series.columns[0]: series.columns[0]+'+'+str(abs(lag))}, axis=1))\n",
    "    #return result\n",
    "    return pd.concat(result, axis=1, names=list(range(+1,-lags))).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decidimos utilizar o número de lags 5, assim foram criadas 5 novas features com os atrasos para a série."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_lags(df, 3)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.reindex(X.index)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados foram separados em treino e teste, para serem utilizado no GridSearch. Como o ScikitLearn separa os dados de validação, o conjunto de teste abaixo já contém o conjunto de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos o GridSearch para encontrar os melhores parâmetros para o KNN. Foram utilizados dois hiperâmetros: o número de vizinhos(n_neighbors) e o peso (weights). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo hiperpâmetros de busca do GridSearch\n",
    "parameters = {'n_neighbors':range(1,20), 'weights':[\"uniform\", \"distance\"]}\n",
    "for p in parameters.items():\n",
    "  print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "knnGS = GridSearchCV(knn, parameters, scoring='neg_mean_absolute_percentage_error', cv=TimeSeriesSplit(n_splits=2, test_size=round(len(df)*0.25)))\n",
    "res = knnGS.fit(X_train, y_train)\n",
    "print(res.best_score_)\n",
    "print(res.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = res.predict(X_test)\n",
    "show_metrics(y_test, prediction, results, 'KNN GS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_ajuste(prediction, y_test.reset_index(drop=True), 'Delhi Temperature - KNN GS MODEL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graf_pred(fitted, train, test, titulo, SVR=False):\n",
    "    \n",
    "    if(SVR==True):\n",
    "        fc = fitted\n",
    "        fc_series = pd.Series(fc, index=test.index[1:])\n",
    "    else:\n",
    "        fc = fitted.forecast(394, alpha=0.05)  # 95% conf\n",
    "        fc_series = pd.Series(fc, index=test.index)\n",
    "\n",
    "    # Plot\n",
    "    #plt.figure(figsize=(12,5), dpi=100)\n",
    "    plt.plot(train, label='Treino')\n",
    "    plt.plot(test, label='Teste')\n",
    "    plt.plot(fc_series, label='Predição')\n",
    "    plt.title(titulo)\n",
    "    plt.legend(loc='upper left', fontsize=8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuos = prediction.flatten() - y_test.reset_index(drop=True).values.flatten()\n",
    "pd.Series(residuos).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(residuos).plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(residuos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima verificamos que o modelo se ajustou bem aos valores reais de acordo com as métricas. No entanto, abaixo foi feito o KNN com a série diferenciada a fim de verificar se há possibilidade de conseguir melhores valores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN com série difenciada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diferenciando\n",
    "X_train_d1 = X_train.diff().dropna()\n",
    "X_test_d1 = X_test.diff().dropna()\n",
    "y_train_d1 = y_train.diff().dropna()\n",
    "y_test_d1 = y_test.diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_diff = knnGS.fit(X_train_d1, y_train_d1)\n",
    "print(res_diff.best_score_)\n",
    "print(res_diff.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_diff = res_diff.predict(X_test_d1)\n",
    "show_metrics(y_test_d1, prediction_diff, results, 'd1 KNN GS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_ajuste(pd.Series(prediction_diff.flatten()), y_test_d1.reset_index(drop=True), 'Delhi - KNN diff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One step \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_ajuste(pd.Series(prediction_diff.flatten()).cumsum(), y_test_d1.reset_index(drop=True).cumsum(), 'Delhi - KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o gráfico apresentou pouco ajuste ao valor real, decidimos utilizar o valor real para ajustar a predição. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_one = y_test.shift(1).reset_index(drop=True).add(pd.Series(prediction_diff.flatten(), name='temperature'),axis=0)\n",
    "graf_ajuste(pred_one, y_test.reset_index(drop=True), 'Delhi Temperature - KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(y_test.iloc[1:-1], pred_one.iloc[1:-1], results, 'pred one KNN GS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuos = prediction_diff.flatten() - y_test_d1.reset_index(drop=True).values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(residuos).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(residuos).plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(residuos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao final do experimento com o KNN, verificamos que foi possível obter melhores resultados com a série diferenciada. No entanto, foi necessário a utilização de valores reais para o ajuste da tendência da série."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui utilizaremos o Support Vector Regression, primeiro vamos ajustar um modelo simples e depois tentar melhorar os parâmetros com o uso do GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "regr = SVR(C=1.0, epsilon=0.2, kernel='linear')\n",
    "\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = regr.predict(X_test)\n",
    "show_metrics(y_test, forecast, results, 'SVR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_ajuste(regr.predict(X_test), y_test.reset_index(drop=True), 'Delhi - SVR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_pred(regr.predict(X_test), df_train, df_test, 'Delhi - SVR', SVR=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que o modelo ajustou muito bem aos dados e fez predições do conjunto de teste muito próximas dos valores reais, como podemos verificar nos gráficos acima e nas métricas de avaliação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos utilizar o GridSearch para explorar diferentes parâmetros e do SVR e encontrar os melhores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':['linear','rbf', 'sigmoid', 'polynomial'], \n",
    "              'C':np.linspace(0.05, 10, 20),\n",
    "              'gamma':np.linspace(.1, 10, 3),\n",
    "              'coef0':np.linspace(.01, 10, 3),\n",
    "              'degree':np.arange(2, 3)\n",
    "              }\n",
    "\n",
    "for p in parameters.items():\n",
    "  print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr2 = SVR()\n",
    "regrGS = GridSearchCV(regr2, parameters, scoring='neg_mean_absolute_percentage_error', cv=TimeSeriesSplit(n_splits=2, test_size=round(len(df)*0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = regrGS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após executar o GridSearch obtivemos como melhor score e parâmetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.best_score_)\n",
    "print(res.best_params_)\n",
    "#{'C': 7.38157894736842, 'coef0': 0.01, 'degree': 2, 'gamma': 0.1, 'kernel': 'linear'}\n",
    "#18 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr2 = SVR(C=10, kernel='linear')\n",
    "res = regr2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = regr2.predict(X_test)\n",
    "show_metrics(y_test, forecast, results, 'SVR GS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_ajuste(res.predict(X_test), y_test.reset_index(drop=True), 'Delhi Temperature - SVR GS MODEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_pred(res.predict(X_test), df_train, df_test, 'Delhi - SVR GS', SVR=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuos = res.predict(X_test).flatten() - y_test.reset_index(drop=True).values.flatten()\n",
    "pd.Series(residuos).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(residuos).plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(residuos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, valid_scores = learning_curve(\n",
    "    SVR(kernel='linear'), X, y, train_sizes=[50,100,150,200,250], cv=TimeSeriesSplit())\n",
    "    #SVR(kernel='linear'), X, y, train_sizes=[np.round(np.array(list(range(0.1,1,0.1))) * len(y))], cv=TimeSeriesSplit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(train_scores.mean(axis=1), index=train_sizes).plot(label='train')\n",
    "pd.Series(valid_scores.mean(axis=1), index=train_sizes).plot(label='val')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do gráfico acima não aparenta haver Overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR com Serie diferenciada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr2 = SVR(C=10, kernel='linear')\n",
    "res = regr2.fit(X_train_d1, y_train_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_diff = regr2.predict(X_test_d1)\n",
    "show_metrics(y_test_d1, forecast_diff, results, 'SVR d1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_ajuste(pd.Series(forecast_diff.flatten()), y_test_d1.reset_index(drop=True), 'Delhi - SVR diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_ajuste(pd.Series(forecast_diff.flatten()).cumsum(), y_test_d1.reset_index(drop=True).cumsum(), 'Delhi - KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_one_svr = y_test.shift(1).reset_index(drop=True).add(pd.Series(forecast_diff.flatten(), name='temperature'),axis=0)\n",
    "graf_ajuste(pred_one_svr, y_test.reset_index(drop=True), 'Delhi Temperature - KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(y_test.iloc[1:-1], pred_one_svr.iloc[1:-1], results, 'pred one SVR diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuos = forecast_diff.flatten() - y_test_d1.reset_index(drop=True).values.flatten()\n",
    "pd.Series(residuos).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(residuos).plot.kde()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(residuos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divisão de Dados MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando os dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=.25)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, shuffle=False, test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diferenciação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diferenciando\n",
    "X_train_d1 = X_train.diff().dropna()\n",
    "X_valid_d1 = X_valid.diff().dropna()\n",
    "X_test_d1 = X_test.diff().dropna()\n",
    "y_train_d1 = y_train.diff().dropna()\n",
    "y_valid_d1 = y_valid.diff().dropna()\n",
    "y_test_d1 = y_test.diff().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d1_norm = X_train_d1.sub(X_train_d1.mean()).div(X_train_d1.std())\n",
    "X_valid_d1_norm = X_valid_d1.sub(X_valid_d1.mean()).div(X_valid_d1.std())\n",
    "X_test_d1_norm = X_test_d1.sub(X_train_d1.mean()).div(X_train_d1.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d1_norm['meantemp-1'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d1_norm['meantemp-1'].plot.hist(title='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_d1_norm['meantemp-1'].plot.hist(title='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_d1_norm['meantemp-1'].plot.hist(title='test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torch.tensor(pd.concat([X_train_d1_norm, y_train_d1], axis=1).values)\n",
    "validating_data = torch.tensor(pd.concat([X_valid_d1_norm, y_valid_d1], axis=1).values)\n",
    "testing_data = torch.tensor(pd.concat([X_test_d1_norm, y_test_d1], axis=1).values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=16, shuffle=False)\n",
    "valid_dataloader = DataLoader(validating_data, batch_size=16, shuffle=False)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \n",
    "    #Config 1\n",
    "    # self.fc1 = nn.Linear(5,100)\n",
    "    # self.fc3 = nn.Linear(100,1)\n",
    "    \n",
    "    #Config 2\n",
    "    # self.fc1 = nn.Linear(5,32)\n",
    "    # self.fc2 = nn.Linear(32,64)\n",
    "    # self.fc3 = nn.Linear(64,1)\n",
    "     \n",
    "    # #Config 3\n",
    "    self.fc1 = nn.Linear(5,32)\n",
    "    self.drop1 = nn.Dropout(p=0.5)\n",
    "    self.fc2 = nn.Linear(32,64)\n",
    "    self.drop2 = nn.Dropout(p=0.5)\n",
    "    self.fc3 = nn.Linear(64,1)\n",
    "  \n",
    "  def forward(self, X):\n",
    "    out = torch.tanh(self.fc1(X))\n",
    "    out = self.drop1(out)\n",
    "    out = torch.relu(self.fc2(out))\n",
    "    out = self.drop2(out)\n",
    "    out = self.fc3(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_neuron = MLP()\n",
    "print(multi_neuron(torch.tensor(X_train_d1.iloc[0]).float()))\n",
    "print(y_train_d1.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_neuron = MLP()\n",
    "epochs = 300\n",
    "loss_fn = nn.MSELoss()\n",
    "#optimizer = optim.RMSprop(multi_neuron.parameters(), lr=0.001)\n",
    "optimizer = optim.SGD(multi_neuron.parameters(), lr=0.01, weight_decay= 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_train = {}\n",
    "history_valid = {}\n",
    "for epoch in range(1, epochs+1):\n",
    "  loss_train = 0.0\n",
    "  for train_data in train_dataloader:\n",
    "    x = train_data[:,:5].float()\n",
    "    y = train_data[:,5].float()\n",
    "  \n",
    "    #forward pass\n",
    "    outputs = multi_neuron(x)\n",
    "\n",
    "    #loss measure\n",
    "    loss = loss_fn(outputs,y)\n",
    "\n",
    "    #backward pass\n",
    "    optimizer.zero_grad() # pára o autograd\n",
    "    loss.backward() # executa o backpropagation\n",
    "    optimizer.step() # atualiza os pesos\n",
    "\n",
    "    loss_train += loss.item() # soma os erros para obter o erro total\n",
    "\n",
    "  loss_valid = 0.0\n",
    "  for valid_data in valid_dataloader:    \n",
    "    x = valid_data[:,:5].float()\n",
    "    y = valid_data[:,5].float()   \n",
    "    #forward pass\n",
    "    target = multi_neuron(x)\n",
    "    #loss measure\n",
    "    loss = loss_fn(outputs,y)\n",
    "    # Calculate Loss\n",
    "    loss_valid += loss.item()\n",
    "\n",
    "\n",
    "  if (epoch % 10 == 0):\n",
    "    print('Epoch{}, train loss {}'.format(epoch, loss_train / len(train_dataloader)))\n",
    "    print('Epoch{}, valid loss {}'.format(epoch, loss_valid / len(valid_dataloader))) # apresenta o erro médio da época\n",
    "  history_train[epoch] = loss_train / len(train_dataloader)\n",
    "  history_valid[epoch] = loss_valid / len(valid_dataloader)\n",
    "\n",
    "pd.Series(history_train).plot()\n",
    "pd.Series(history_valid).plot()\n",
    "\n",
    "#pd.Series(train_scores.mean(axis=1), index=train_sizes).plot(label='train')\n",
    "#pd.Series(valid_scores.mean(axis=1), index=train_sizes).plot(label='val')\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(history_train).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_neuron.eval()\n",
    "results_MLP = []\n",
    "for test_data in test_dataloader:\n",
    "    x = test_data[:,:5].float()\n",
    "    y = test_data[:,5].float()\n",
    "    \n",
    "    y_pred = multi_neuron(x)\n",
    "    results_MLP.extend(y_pred.flatten().detach().numpy())\n",
    "#pd.DataFrame(results).plot()\n",
    "results_MLP[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.Series(results_MLP, name='pred'), y_test_d1.reset_index(drop=True)],axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(y_test_d1,results_MLP, results, 'MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dúvidas\n",
    "\n",
    "- Pela metodologia Box and Jenkins podemos usar o AUTO ARIMA ou devemos testar na mão diferentes ARIMAS?\n",
    "\n",
    "- Como devemos fazer a previsao do ARIMA? Atualmente, estamos utilizando forecast e colocando o tamanho do conjunto de observações do teste, é isso mesmo?\n",
    "\n",
    "- O modelo que acreditamos que era melhor não bateu com o do auto-arima e agora?\n",
    "\n",
    "- Nossa predição do ARIMA tá bem estranha, ficou uma linha. Achamos estranho, pois nossa série parece bem comportada.\n",
    "\n",
    "- Para fazer a validação com 10 repetições no GridSearch, fizemos uso de n_splits = 10 dentro de TimeSeriesSplit, é isso mesmo? -> Se for isso, como vamos dividir em 25% de validação? \n",
    "\n",
    "- Devemos fazer essa mesma metodologia de n_splits = 10 na MLP? Porque parece bem trabalhoso, pois não sabemos como o pytorch faria isso, devemos escrever o código? "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "578d23e9265697bad3ff07bcff4c72684a1087c3ecac6cf42decc0cb53b76ed7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
